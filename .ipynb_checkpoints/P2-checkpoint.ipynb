{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "\n",
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "Below are some helper functions to help get you started. They should look familiar from the lesson!\n",
    "\n",
    "\n",
    "**Run the cell below to import some packages.  If you get an `import error` for a package you've already installed, try changing your kernel (select the Kernel menu above --> Change Kernel).  Still have problems?  Try relaunching Jupyter Notebook from the terminal prompt.  Also, consult the forums for more troubleshooting tips.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "#%matplotlib qt\n",
    "%matplotlib inline\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    `vertices` should be a numpy array of integer points.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "    \n",
    "\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to saturation scale\n",
    "    hls = cv2.cvtColor(img,cv2.COLOR_RGB2HLS)\n",
    "    sat = hls[:,:,2] # extract satuarion for yellow\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(sat,cv2.CV_64F,1,0,ksize=sobel_kernel)\n",
    "    elif orient == 'y':\n",
    "        sobel = cv2.Sobel(sat,cv2.CV_64F,0,1,ksize=sobel_kernel)\n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scale_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    binary_output = np.zeros_like(sat)\n",
    "    binary_output[(scale_sobel > thresh[0]) & (scale_sobel < thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return binary_output\n",
    "\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to saturation scale\n",
    "    hls = cv2.cvtColor(img,cv2.COLOR_RGB2HLS)\n",
    "    sat = hls[:,:,2] # extract satuarion for yellow\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobel_x = cv2.Sobel(sat,cv2.CV_64F,1,0,ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(sat,cv2.CV_64F,0,1,ksize=sobel_kernel)\n",
    "    # 3) Calculate the magnitude \n",
    "    sobel_mag = np.sqrt(np.power(sobel_x,2)+np.power(sobel_y,2))\n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    scale_sobel = np.uint8(255*sobel_mag/np.max(sobel_mag))\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    binary_output = np.zeros_like(sat)\n",
    "    binary_output[(scale_sobel > mag_thresh[0]) & (scale_sobel < mag_thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return binary_output\n",
    "\n",
    "def color_select(img,gray_threshold):\n",
    "    \"\"\"\n",
    "    Find the white color inside the image\n",
    "    \"\"\"\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # 2) Create a binary mask where mag thresholds are met\n",
    "    binary_output = np.zeros_like(gray)\n",
    "    color_ind = (gray>gray_threshold)\n",
    "    binary_output[color_ind] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return binary_output\n",
    "\n",
    "def img_unwarp(img, mtx, dist):\n",
    "    \"\"\"\n",
    "    This function will undistrot the image and gernerate top-down view of image\n",
    "    \"\"\"\n",
    "    undist_img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "    # 1) Measure the source point and it's destination couterpart. \n",
    "    src = np.float32([[223,719], # lower left corner\n",
    "                      [582,456], # upper left corner \n",
    "                      [694,456], # upper right corner\n",
    "                      [1087,719]]) # lower right corner\n",
    "\n",
    "    dst = np.float32([[320,720], # lower left corner\n",
    "                      [320,0], # upper left corner \n",
    "                      [960,0], # upper right corner\n",
    "                      [960,720]]) # lower right corner\n",
    "    # 2) use cv2.getPerspectiveTransform() to get M, the transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src,dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst,src)\n",
    "\n",
    "    # 3) use cv2.warpPerspective() to warp your image to a top-down view\n",
    "    img_size = (undist_img.shape[1],undist_img.shape[0])\n",
    "    warped = cv2.warpPerspective(undist_img,M,img_size,flags=cv2.INTER_LINEAR)\n",
    "    return warped, M, Minv, src\n",
    "\n",
    "\n",
    "def find_lane_pixels(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result. Need to have 3 channels\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    # leftx_base & rightx_base is based on bottom half of the image (NOT SLIDING WINDOWS)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    # The reason to add '+ midpoint' is that rightx_base need to pass the midpoint\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    'Why do we need this????'\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero() # Return the indices of non-zero value, in 2 1-D-arrays having same length\n",
    "    nonzeroy = np.array(nonzero[0]) # The first array is y-dimension\n",
    "    nonzerox = np.array(nonzero[1]) # The second array is x-dimension\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        ### TO-DO: Find the four below boundaries of the window ###\n",
    "        win_xleft_low = leftx_current-margin  # left window, lower x\n",
    "        win_xleft_high = leftx_current+margin  # left window, higher x\n",
    "        win_xright_low = rightx_current-margin  # right window, lower x\n",
    "        win_xright_high = rightx_current+margin  # right window, higher x\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), thickness=2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), thickness=2) \n",
    "        \n",
    "        ### TO-DO: Identify the number nonzero pixels in x and y within the window ###\n",
    "        'Good_left/right_inds stores the indices of nonzero coordiate inside the windows'\n",
    "        good_left_inds = ((nonzerox>win_xleft_low) & (nonzerox<win_xleft_high) &\n",
    "                          (nonzeroy>win_y_low) & (nonzeroy<win_y_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzerox>win_xright_low) & (nonzerox<win_xright_high) &\n",
    "                           (nonzeroy>win_y_low) & (nonzeroy<win_y_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        ### TO-DO: If you found > minpix pixels, recenter next window ###\n",
    "        ### (`right` or `leftx_current`) on their MEAN position ###\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:\n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "        \n",
    "        \n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    # Instead of list of lists, concatenate() would concvert it to 1D-aaray\n",
    "    'The reason use **try** statement here is that let the code still move forward even when concatenate() fail.'\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        'How could we tell whether or not the above is implemented fully? If not, whats going to happen?'\n",
    "        pass\n",
    "    #After this code, left_lane_inds containt all the indices of pixel INSIDE the windows. \n",
    "    \n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "\n",
    "def fit_polynomial(binary_warped):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "\n",
    "    ### TO-DO: Fit a second order polynomial to each using `np.polyfit` ###\n",
    "    '''\n",
    "    Take note of how we fit the lines above - while normally you CALCULATE A Y-VALUE FOR A\n",
    "    GIVEN X,here we do the opposite. Why? Because we expect our lane lines to be (mostly) \n",
    "    vertically-oriented.\n",
    "    '''\n",
    "    left_fit = np.polyfit(lefty,leftx,2)\n",
    "    left_fit_1d = np.poly1d(left_fit)\n",
    "    right_fit = np.polyfit(righty,rightx,2)\n",
    "    right_fit_1d = np.poly1d(right_fit)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_fitx=left_fit_1d(ploty)\n",
    "        right_fitx=right_fit_1d(ploty)\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "    \n",
    "    lane_pixel_ind=(leftx,lefty,rightx,righty)\n",
    "    fit_1d=(left_fit_1d,right_fit_1d)\n",
    "    polyfit_pts=(left_fitx,right_fitx,ploty)\n",
    "\n",
    "    return out_img,lane_pixel_ind,fit_1d,polyfit_pts\n",
    "\n",
    "def measure_curvature_real(binary_warped, xm_per_pix, ym_per_pix,lane_pixel_ind):\n",
    "    leftx = lane_pixel_ind[0]\n",
    "    lefty = lane_pixel_ind[1]\n",
    "    rightx = lane_pixel_ind[2]\n",
    "    righty = lane_pixel_ind[3]\n",
    "\n",
    "    ### TO-DO: Fit a second order polynomial to each using `np.polyfit` ###\n",
    "    '''\n",
    "    Take note of how we fit the lines above - while normally you CALCULATE A Y-VALUE FOR A\n",
    "    GIVEN X,here we do the opposite. Why? Because we expect our lane lines to be (mostly) \n",
    "    vertically-oriented.\n",
    "    '''\n",
    "    left_fit_cr = np.polyfit(ym_per_pix*lefty,xm_per_pix*leftx,2)\n",
    "    left_fit_cr_1d = np.poly1d(left_fit_cr)\n",
    "    right_fit_cr = np.polyfit(ym_per_pix*righty,xm_per_pix*rightx,2)\n",
    "    right_fit_cr_1d = np.poly1d(right_fit_cr)\n",
    "    \n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_cr_fitx=left_fit_cr_1d(ploty)\n",
    "        right_cr_fitx=right_fit_cr_1d(ploty)\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_cr_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_cr_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = ym_per_pix*np.max(ploty)\n",
    "    \n",
    "    ##### TO-DO: Implement the calculation of R_curve (radius of curvature) #####\n",
    "    left_curverad = np.power(1+(2*left_fit_cr[0]*y_eval+left_fit_cr[1])**2,1.5)/np.absolute(2*left_fit_cr[0])\n",
    "        ## Implement the calculation of the left line here\n",
    "    right_curverad = np.power(1+(2*right_fit_cr[0]*y_eval+right_fit_cr[1])**2,1.5)/np.absolute(2*right_fit_cr[0])\n",
    "        ## Implement the calculation of the right line here\n",
    "\n",
    "    return left_curverad, right_curverad\n",
    "\n",
    "def vehicle_offset(img,xm_per_pix,fit_1d):\n",
    "    left_fit_1d = fit_1d[0]\n",
    "    right_fit_1d = fit_1d[1]\n",
    "    '''\n",
    "    Calculate the offset of vehicle to center of the lane\n",
    "    '''\n",
    "    y_eval = np.max(img.shape[0])\n",
    "    lane_ctr_x = np.mean(right_fit_1d(y_eval)-left_fit_1d(y_eval))\n",
    "    vehicle_ctr_x = img.shape[1]/2\n",
    "    offset_x = xm_per_pix*(vehicle_ctr_x-lane_ctr_x) # unit: meter\n",
    "    \n",
    "    return offset_x\n",
    "\n",
    "def lane_highlight(undist, warped, Minv, polyfit_pts):\n",
    "    left_fitx = polyfit_pts[0]\n",
    "    right_fitx = polyfit_pts[1]\n",
    "    ploty = polyfit_pts[2]\n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (undist.shape[1], undist.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    return result\n",
    "\n",
    "                        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Camera Calibration\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "Expected input & output\n",
    "<img src=\"./examples/undistort_output.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Camera distorsion calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "#%matplotlib inline\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "nx = 9\n",
    "ny = 6\n",
    "\n",
    "objp = np.zeros((ny*nx,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx,ny),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "    else: print('No chess board corner found and the filename is %s'%(fname))\n",
    "\n",
    "    # Draw and display the corners\n",
    "    img = cv2.drawChessboardCorners(img, (nx,ny), corners, ret)\n",
    "    cv2.imshow('img',img)\n",
    "    cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Distorsion image trail\n",
    "If the above cell ran sucessfully, you should now have `objpoints` and `imgpoints` needed for camera calibration.  Run the cell below to calibrate, calculate distortion coefficients, and test undistortion on an image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_size is (1280, 720)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Test undistortion on an image\n",
    "img = cv2.imread('camera_cal/test_image.jpg')\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "print(\"img_size is\",img_size)\n",
    "\n",
    "# Do camera calibration given object points and image points\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "\n",
    "\n",
    "dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "cv2.imwrite('camera_cal/test_undist.jpg',dst)\n",
    "\n",
    "# Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "# Create libary to store all the specs\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "# pickle.dump() is to dump/store/serialize the library dist_pickle = {} to the dest directory \n",
    "# so that we could retrieve this library later on OHTER python application.\n",
    "pickle.dump( dist_pickle, open( \"camera_cal/wide_dist_mtx.p\", \"wb\" ) )\n",
    "#dst = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(dst)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)\n",
    "f.savefig('test_images_output/chessboard_undistort_output.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pipeline Single Image\n",
    "\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Provide an example of a distortion-corrected image.\n",
    "\n",
    "<img src=\"./test_images/test1.jpg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Describe how (and identify where in your code) you used color transforms, gradients or other methods to create a thresholded binary image. Provide an example of a binary image result.\n",
    "\n",
    "<img src=\"./examples/binary_combo_example.jpg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saturation Sacle & Gray Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in an image\n",
    "#filename = 'test1.jpg'\n",
    "filename = 'straight_lines1.jpg'\n",
    "img = mpimg.imread('test_images/'+filename)\n",
    "\n",
    "# Choose a Sobel kernel size\n",
    "ksize = 3 # Choose a larger odd number to smooth gradient measurements\n",
    "\n",
    "# Apply each of the thresholding functions\n",
    "gradx = abs_sobel_thresh(img, orient='x', sobel_kernel=ksize, thresh=(20, 100))\n",
    "grady = abs_sobel_thresh(img, orient='y', sobel_kernel=ksize, thresh=(20, 100))\n",
    "mag_binary = mag_thresh(img, sobel_kernel=ksize, mag_thresh=(30, 100))\n",
    "\n",
    "# Apply the color selection\n",
    "rgb_threshold = 200\n",
    "color_binary = color_select(img, rgb_threshold)\n",
    "\n",
    "combined = np.zeros_like(mag_binary)\n",
    "combined[((gradx == 1) & (grady == 1)) | (mag_binary == 1) | (color_binary == 1)] = 1\n",
    "\n",
    "# Plot the result\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(combined, cmap='gray')\n",
    "ax2.set_title('Combined.', fontsize=50)\n",
    "f.savefig('test_images_output/binary_output.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Plot the trail result for different criteria\n",
    "f, a = plt.subplots(3, 2, figsize=(24, 24))\n",
    "#f.tight_layout()\n",
    "a[0][0].imshow(img)\n",
    "a[0][0].set_title('Original Image', fontsize=50)\n",
    "a[0][1].imshow(gradx, cmap='gray')\n",
    "a[0][1].set_title('gradx', fontsize=50)\n",
    "a[1][0].imshow(grady, cmap='gray')\n",
    "a[1][0].set_title('grady', fontsize=50)\n",
    "a[1][1].imshow(mag_binary, cmap='gray')\n",
    "a[1][1].set_title('mag_binary', fontsize=50)\n",
    "a[2][0].imshow(color_binary, cmap='gray')\n",
    "a[2][0].set_title('color_binary', fontsize=50)\n",
    "a[2][1].imshow(combined, cmap='gray')\n",
    "a[2][1].set_title('Combined.', fontsize=50)\n",
    "f.savefig('test_images_output/binary_output_clustered.jpg')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Region masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertices is [[[ 200  720]\n",
      "  [1200  720]\n",
      "  [ 780  400]\n",
      "  [ 550  400]]]\n"
     ]
    }
   ],
   "source": [
    "# Define the vertices of the region of masking\n",
    "\n",
    "left_bottom = [200, 720]\n",
    "left_upper = [550, 400]\n",
    "right_upper = [780,400]\n",
    "right_bottom = [1200, 720]\n",
    "vertices = np.array([[left_bottom, right_bottom,right_upper, left_upper]],dtype=np.int32)\n",
    "print('vertices is',vertices)\n",
    "\n",
    "binary_mask = region_of_interest(combined, vertices)\n",
    "\n",
    "# Plot the result\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(combined,cmap='gray')\n",
    "ax1.set_title('Image Before Masking', fontsize=50)\n",
    "ax2.imshow(binary_mask, cmap='gray')\n",
    "ax2.set_title('Image after Masking', fontsize=50)\n",
    "f.savefig('test_images_output/binary_output_masking.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.Describe how (and identify where in your code) you performed a perspective transform and provide an example of a transformed image.\n",
    "\n",
    "| Source        | Destination   | \n",
    "|:-------------:|:-------------:| \n",
    "| 223, 719      | 320, 720      | \n",
    "| 582, 456      | 320, 0        |\n",
    "| 694, 456      | 960, 0        |\n",
    "| 1087, 719     | 960, 720      |\n",
    "\n",
    "\n",
    "<img src=\"./examples/warped_straight_lines.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read in the saved camera matrix and distortion coefficients\n",
    "# These are the arrays you calculated using cv2.calibrateCamera()\n",
    "dist_pickle = pickle.load( open( \"camera_cal/wide_dist_mtx.p\", \"rb\" ) )\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "\n",
    "top_down, perspective_M, perspective_Minv, src = img_unwarp(binary_mask, mtx, dist)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.plot(src[::,0],src[::,1],'or',markersize=12,alpha=0.7)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(top_down,cmap='gray')\n",
    "ax2.set_title('Undistorted and Warped Image', fontsize=50)\n",
    "#plt.subplots_adjust(left=0.1, right=1, top=1, bottom=0.9)\n",
    "f.savefig('test_images_output/perspectivetransform_output.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Describe how (and identify where in your code) you identified lane-line pixels and fit their positions with a polynomial?\n",
    "\n",
    "Then I did some other stuff and fit my lane lines with a 2nd order polynomial kinda like this:\n",
    "\n",
    "<img src=\"./examples/color_fit_lines.jpg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "td_mark, lane_pixel_ind, fit_1d, polyfit_pts = fit_polynomial(top_down)\n",
    "\n",
    "plt.imshow(td_mark)\n",
    "# Plots the left and right polynomials on the lane lines\n",
    "#polyfit_pts=(left_fitx,right_fitx,ploty)\n",
    "plt.plot(polyfit_pts[0], polyfit_pts[2], color='yellow')\n",
    "plt.plot(polyfit_pts[1], polyfit_pts[2], color='yellow')\n",
    "plt.savefig('test_images_output/perspectivetransform_boxandline.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Describe how (and identify where in your code) you calculated the radius of curvature of the lane and the position of the vehicle with respect to center.\n",
    "\n",
    "I did this in lines # through # in my code in my_other_file.py\n",
    "\n",
    "[road marking](https://www.civil.iitb.ac.in/~vmtom/1100_LnTse/525_lnTse/plain/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vehicle is 0.13m left of center\n",
      "Left lane curvature is 630.95m\n",
      "Right lane curvature is 754.90m \n"
     ]
    }
   ],
   "source": [
    "xm_per_pix = 3.7/640 # meters per pixel in x dimension\n",
    "ym_per_pix = 12/720 # meters per pixel in y dimension\n",
    "#ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "\n",
    "# Calculate the radius of curvature in meters for both lane lines\n",
    "left_curverad, right_curverad = measure_curvature_real(td_mark,xm_per_pix,ym_per_pix,lane_pixel_ind)\n",
    "\n",
    "# Calculate the offset of vehicle to center of the lane\n",
    "offset_x = vehicle_offset(img,xm_per_pix,fit_1d) #unit: meter\n",
    "\n",
    "\n",
    "if offset_x > 0:\n",
    "    output = \"Vehicle is %.2fm right of center\\n\" %np.absolute(offset_x)\n",
    "else:\n",
    "    output = \"Vehicle is %.2fm left of center\\n\" %np.absolute(offset_x)\n",
    "output = output + 'Left lane curvature is %.2fm\\nRight lane curvature is %.2fm '\\\n",
    "        %(left_curverad,right_curverad)\n",
    "    \n",
    "print(output)\n",
    "\n",
    "f,ax1 = plt.subplots(1,1)\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax1.text(100,200, output, fontsize=15, color='white')\n",
    "f.savefig('test_images_output/original_curvature_offset.jpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. Provide an example image of your result plotted back down onto the road such that the lane area is identified clearly.\n",
    "\n",
    "I implemented this step in lines # through # in my code in yet_another_file.py in the function map_lane(). Here is an example of my result on a test image:\n",
    "\n",
    "<img src=\"./examples/example_output.jpg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(lane_highlight(img,top_down,perspective_Minv,polyfit_pts))\n",
    "plt.savefig('test_images_output/original_highlightedlane.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pipeline Multiple Images\n",
    "\n",
    "Build the pipeline and run your solution on all test_images. Make copies into the `test_images_output` directory, and you can use the images in your writeup report.\n",
    "\n",
    "Try tuning the various parameters, especially the low and high Canny thresholds as well as the Hough lines parameters.\n",
    "\n",
    "TODO: Build your pipeline that will draw lane lines on the test_images\n",
    "\n",
    "then save them to the test_images_output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output images will be saved to /test_images_output\n",
      "process test6.jpg ...\n",
      "This image is: <class 'numpy.ndarray'> with dimensions: (720, 1280, 3)\n",
      "process test5.jpg ...\n",
      "This image is: <class 'numpy.ndarray'> with dimensions: (720, 1280, 3)\n",
      "process test4.jpg ...\n",
      "This image is: <class 'numpy.ndarray'> with dimensions: (720, 1280, 3)\n",
      "process test1.jpg ...\n",
      "This image is: <class 'numpy.ndarray'> with dimensions: (720, 1280, 3)\n",
      "process test3.jpg ...\n",
      "This image is: <class 'numpy.ndarray'> with dimensions: (720, 1280, 3)\n",
      "process test2.jpg ...\n",
      "This image is: <class 'numpy.ndarray'> with dimensions: (720, 1280, 3)\n",
      "process straight_lines2.jpg ...\n",
      "This image is: <class 'numpy.ndarray'> with dimensions: (720, 1280, 3)\n",
      "process straight_lines1.jpg ...\n",
      "This image is: <class 'numpy.ndarray'> with dimensions: (720, 1280, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "%matplotlib qt\n",
    "\n",
    "# Create output directory\n",
    "if os.path.exists(\"test_images_output/\"):\n",
    "    print('Output images will be saved to /test_images_output')\n",
    "else: \n",
    "    print('Directory will be created: /test_images_output')\n",
    "    os.makedirs(\"test_images_output/\")\n",
    "\n",
    "directory = os.listdir(\"test_images/\")\n",
    "    \n",
    "\n",
    "# Choose a Sobel kernel size\n",
    "ksize = 3 # Choose a larger odd number to smooth gradient measurements\n",
    "    \n",
    "# Define the vertices of the region of masking\n",
    "left_bottom = [200, 720]\n",
    "left_upper = [550, 400]\n",
    "right_upper = [780,400]\n",
    "right_bottom = [1200, 720]   \n",
    "vertices = np.array([[left_bottom, right_bottom,right_upper, left_upper]],dtype=np.int32)\n",
    "    \n",
    "# Read in the saved camera matrix and distortion coefficients\n",
    "dist_pickle = pickle.load( open( \"camera_cal/wide_dist_mtx.p\", \"rb\" ) )\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "\n",
    "# Set the conversion ratio between the pixel and actual distance\n",
    "xm_per_pix = 3.7/640 # meters per pixel in x dimension\n",
    "ym_per_pix = 12/720 # meters per pixel in y dimension\n",
    "    \n",
    "    \n",
    "for filename in directory:\n",
    "#for filename in ['straight_lines1.jpg']:\n",
    "    \n",
    "    # reading in an image\n",
    "    img = mpimg.imread('test_images/'+filename)\n",
    "    print('process %s ...'%(filename))\n",
    "\n",
    "    # printing out some stats and plotting\n",
    "    print('This image is with dimensions:', img.shape)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Create Binary Image\n",
    "    '''\n",
    "\n",
    "    # Apply each of the thresholding functions\n",
    "    gradx = abs_sobel_thresh(img, orient='x', sobel_kernel=ksize, thresh=(20, 100))\n",
    "    grady = abs_sobel_thresh(img, orient='y', sobel_kernel=ksize, thresh=(20, 100))\n",
    "    mag_binary = mag_thresh(img, sobel_kernel=ksize, mag_thresh=(30, 100))\n",
    "\n",
    "    # Apply the color selection\n",
    "    rgb_threshold = 200\n",
    "    color_binary = color_select(img, rgb_threshold)\n",
    "\n",
    "    combined = np.zeros_like(mag_binary)\n",
    "    combined[((gradx == 1) & (grady == 1)) | (mag_binary == 1) | (color_binary == 1)] = 1\n",
    "    \n",
    "    '''\n",
    "    Masking Binary Image\n",
    "    '''\n",
    "    binary_mask = region_of_interest(combined, vertices)\n",
    "    \n",
    "    '''\n",
    "    Unwarp Binary Image\n",
    "    '''\n",
    "    top_down, perspective_M, perspective_Minv, src = img_unwarp(binary_mask, mtx, dist)\n",
    "    \n",
    "    '''\n",
    "    Polyfit Binary Image\n",
    "    '''\n",
    "    td_mark, lane_pixel_ind, fit_1d, polyfit_pts = fit_polynomial(top_down)\n",
    "    \n",
    "    '''\n",
    "    Calculate the radius of curvature & vehicle offset\n",
    "    '''\n",
    "    # Calculate the radius of curvature in meters for both lane lines\n",
    "    left_curverad, right_curverad = measure_curvature_real(td_mark,xm_per_pix,ym_per_pix,lane_pixel_ind)\n",
    "\n",
    "    # Calculate the offset of vehicle to center of the lane\n",
    "    offset_x = vehicle_offset(img,xm_per_pix,fit_1d) #unit: meter\n",
    "    \n",
    "    if offset_x > 0:\n",
    "        output = \"Vehicle is %.2fm right of center\\n\" %np.absolute(offset_x)\n",
    "    else:\n",
    "        output = \"Vehicle is %.2fm left of center\\n\" %np.absolute(offset_x)\n",
    "    output = output + 'Left lane curvature is %.2fm\\nRight lane curvature is %.2fm'%(left_curverad, right_curverad) \n",
    "    \n",
    "    '''\n",
    "    Height light the lane\n",
    "    '''\n",
    "    img_output = lane_highlight(img,top_down,perspective_Minv,polyfit_pts)\n",
    "    \n",
    "    '''\n",
    "    Output the image\n",
    "    '''    \n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=50)\n",
    "    ax2.imshow(img_output)\n",
    "    ax2.set_title('Output Image', fontsize=50)\n",
    "    ax2.text(100,200, output, fontsize=15, color='white')\n",
    "    f.savefig('test_images_output/%s_output.jpg'%filename)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pipeline Video\n",
    "\n",
    "You know what's cooler than drawing lanes over images? Drawing lanes over video!\n",
    "\n",
    "We can test our solution on two provided videos:\n",
    "\n",
    "`project_video.mp4`\n",
    "\n",
    "**Note: if you get an import error when you run the next cell, try changing your kernel (select the Kernel menu above --> Change Kernel). Still have problems? Try relaunching Jupyter Notebook from the terminal prompt. Also, consult the forums for more troubleshooting tips.**\n",
    "\n",
    "**If you get an error that looks like this:**\n",
    "```\n",
    "NeedDownloadError: Need ffmpeg exe. \n",
    "You can download it by calling: \n",
    "imageio.plugins.ffmpeg.download()\n",
    "```\n",
    "**Follow the instructions in the error message and check out [this forum post](https://discussions.udacity.com/t/project-error-of-test-on-videos/274082) for more troubleshooting tips across operating systems.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "def fit_poly(img_shape, leftx, lefty, rightx, righty):\n",
    "    ### TO-DO: Fit a second order polynomial to each with np.polyfit() ###\n",
    "    left_fit = np.polyfit(lefty,leftx,2)\n",
    "    left_fit_1d = np.poly1d(left_fit)\n",
    "    right_fit = np.polyfit(righty,rightx,2)\n",
    "    right_fit_1d = np.poly1d(right_fit)\n",
    "    print(\"left_fit is\",left_fit)\n",
    "    print(\"right_fit is\",right_fit)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "    ### TO-DO: Calc both polynomials using ploty, left_fit and right_fit ###\n",
    "    left_fitx = left_fit_1d(ploty)\n",
    "    right_fitx = right_fit_1d(ploty)\n",
    "    \n",
    "    fit_1d=(left_fit_1d,right_fit_1d)\n",
    "    polyfit_pts=(left_fitx,right_fitx,ploty)\n",
    "    \n",
    "    return polyfit_pts, fit_1d\n",
    "\n",
    "def fit_around_poly(binary_warped,left_fit_1d_0,right_fit_1d_0):\n",
    "    # HYPERPARAMETER\n",
    "    # Choose the width of the margin around the previous polynomial to search\n",
    "    # The quiz grader expects 100 here, but feel free to tune on your own!\n",
    "    margin = 100\n",
    "\n",
    "    # Grab activated pixels\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    ### TO-DO: Set the area of search based on activated x-values ###\n",
    "    ### within the +/- margin of our polynomial function ###\n",
    "    ### Hint: consider the window areas for the similarly named variables ###\n",
    "    ### in the previous quiz, but change the windows to our NEW search area ###\n",
    "    '''\n",
    "    During the array comparison, it would compare the indices to indices, and return the\n",
    "    indice with each comparison! NOT the entire array\n",
    "    '''\n",
    "    ### use PRIOR left_fit_1d_0 & right_fit_1d_0 to find new indice\n",
    "    ### left_lane_inds & right_lane_inds are indices for NEW img\n",
    "    left_lane_inds = ((nonzerox>(left_fit_1d_0(nonzeroy)-margin)) & \n",
    "                      (nonzerox<(left_fit_1d_0(nonzeroy)+margin))).nonzero()[0]\n",
    "    right_lane_inds = ((nonzerox>(right_fit_1d_0(nonzeroy)-margin)) & \n",
    "                       (nonzerox<(right_fit_1d_0(nonzeroy)+margin))).nonzero()[0]\n",
    "\n",
    "    \n",
    "    # Again, extract left and right line pixel positions for NEW img\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Fit NEW polynomials\n",
    "    polyfit_pts, fit_1d = fit_poly(binary_warped.shape, leftx, lefty, rightx, righty)\n",
    "    left_fit_1d = fit_1d[0]\n",
    "    right_fit_1d = fit_1d[1]\n",
    "    left_fitx = polyfit_pts[0]\n",
    "    right_fitx = polyfit_pts[1]\n",
    "    ploty = polyfit_pts[2]\n",
    "    \n",
    "    ## Visualization ##\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                              ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                              ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    \n",
    "    # Plot the polynomial lines onto the image\n",
    "    #plt.plot(left_fitx, ploty, color='yellow')\n",
    "    #plt.plot(right_fitx, ploty, color='yellow')\n",
    "    ## End visualization steps ##\n",
    "    \n",
    "    lane_pixel_ind=(leftx,lefty,rightx,righty)\n",
    "    \n",
    "    return result,lane_pixel_ind,fit_1d,polyfit_pts\n",
    "\n",
    "\n",
    "\n",
    "#Main function\n",
    "def process_image(img):\n",
    "    \n",
    "    # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "    # TODO: put your pipeline here,\n",
    "    # you should return the final output (image where lines are drawn on lanes)\n",
    "    \n",
    "    '''\n",
    "    Create Binary Image\n",
    "    '''\n",
    "\n",
    "    # Apply each of the thresholding functions\n",
    "    gradx = abs_sobel_thresh(img, orient='x', sobel_kernel=ksize, thresh=(20, 100))\n",
    "    grady = abs_sobel_thresh(img, orient='y', sobel_kernel=ksize, thresh=(20, 100))\n",
    "    mag_binary = mag_thresh(img, sobel_kernel=ksize, mag_thresh=(30, 100))\n",
    "\n",
    "    # Apply the color selection\n",
    "    rgb_threshold = 200\n",
    "    color_binary = color_select(img, rgb_threshold)\n",
    "\n",
    "    combined = np.zeros_like(mag_binary)\n",
    "    combined[((gradx == 1) & (grady == 1)) | (mag_binary == 1) | (color_binary == 1)] = 1\n",
    "    \n",
    "    '''\n",
    "    Masking Binary Image\n",
    "    '''\n",
    "    binary_mask = region_of_interest(combined, vertices)\n",
    "    \n",
    "    '''\n",
    "    Unwarp Binary Image\n",
    "    '''\n",
    "    top_down, perspective_M, perspective_Minv, src = img_unwarp(binary_mask, mtx, dist)\n",
    "    \n",
    "    '''\n",
    "    Polyfit Binary Image\n",
    "    '''\n",
    "    global count\n",
    "    global left_fit_1d\n",
    "    global right_fit_1d\n",
    "    \n",
    "    if (count == 0):\n",
    "        td_mark, lane_pixel_ind, fit_1d, polyfit_pts = fit_polynomial(top_down)\n",
    "        left_fit_1d = fit_1d[0]\n",
    "        right_fit_1d = fit_1d[1]\n",
    "        count = count + 1\n",
    "    else:\n",
    "        td_mark, lane_pixel_ind, fit_1d, polyfit_pts = fit_around_poly(top_down,left_fit_1d,right_fit_1d)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Polyfit Binary Image\n",
    "    td_mark, lane_pixel_ind, fit_1d_0, polyfit_pts = fit_polynomial(top_down)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    Calculate the radius of curvature & vehicle offset\n",
    "    '''\n",
    "    # Calculate the radius of curvature in meters for both lane lines\n",
    "    left_curverad, right_curverad = measure_curvature_real(td_mark,xm_per_pix,ym_per_pix,lane_pixel_ind)\n",
    "\n",
    "    # Calculate the offset of vehicle to center of the lane\n",
    "    offset_x = vehicle_offset(img,xm_per_pix,fit_1d) #unit: meter\n",
    "    \n",
    "    if offset_x > 0:\n",
    "        output = \"Vehicle is %.2fm right of center\" %np.absolute(offset_x)\n",
    "    else:\n",
    "        output = \"Vehicle is %.2fm left of center\" %np.absolute(offset_x)\n",
    "    \n",
    "    '''\n",
    "    Height light the lane\n",
    "    '''\n",
    "    img_output = lane_highlight(img,top_down,perspective_Minv,polyfit_pts)\n",
    "    \n",
    "    cv2.putText(img_output, output, (100, 100), cv2.FONT_HERSHEY_DUPLEX, 2, (255,255,255), thickness=2)\n",
    "    cv2.putText(img_output, 'Left lane curvature is %.2fm'%left_curverad, (100, 150), cv2.FONT_HERSHEY_DUPLEX, 2, (255,255,255), thickness=2)\n",
    "    cv2.putText(img_output, 'Right lane curvature is %.2fm'%right_curverad, (100, 200), cv2.FONT_HERSHEY_DUPLEX, 2, (255,255,255), thickness=2) \n",
    "\n",
    "    return img_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the one with the solid white lane on the right first ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output videos will be saved to /test_videos_output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \n",
      "t:   2%|▏         | 2/125 [48:22<00:44,  2.78it/s, now=None]\n",
      "                                                            [A\n",
      "t:   2%|▏         | 2/125 [48:22<00:44,  2.78it/s, now=None]\n",
      "t:   9%|▉         | 8/90 [43:04<00:40,  2.05it/s, now=None]\u001b[A\n",
      "\n",
      "t:   0%|          | 0/75 [00:00<?, ?it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video test_videos_output/project_video.mp4.\n",
      "Moviepy - Writing video test_videos_output/project_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:   3%|▎         | 2/75 [00:00<00:10,  7.17it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.88948190e-04  3.34514640e-01  2.72278491e+02]\n",
      "right_fit is [-2.88326868e-04  4.05791897e-01  8.93171869e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:   4%|▍         | 3/75 [00:01<00:25,  2.85it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-3.01035440e-04  3.50556710e-01  2.68767781e+02]\n",
      "right_fit is [-2.68440509e-04  4.05418060e-01  8.85358423e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:   5%|▌         | 4/75 [00:01<00:25,  2.78it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-3.08969958e-04  3.58549426e-01  2.67167539e+02]\n",
      "right_fit is [-2.60833852e-04  4.06695976e-01  8.81334451e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:   7%|▋         | 5/75 [00:01<00:23,  2.97it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-3.03972933e-04  3.60156462e-01  2.65780928e+02]\n",
      "right_fit is [-2.50129189e-04  4.10173166e-01  8.74977336e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:   8%|▊         | 6/75 [00:02<00:21,  3.15it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-3.00799845e-04  3.60810780e-01  2.64612868e+02]\n",
      "right_fit is [-2.43545702e-04  4.09941215e-01  8.72199561e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:   9%|▉         | 7/75 [00:02<00:20,  3.35it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-3.02045890e-04  3.66588129e-01  2.62849422e+02]\n",
      "right_fit is [-2.34182511e-04  4.10339401e-01  8.66998613e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  11%|█         | 8/75 [00:02<00:19,  3.41it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.84547603e-04  3.58735403e-01  2.61570474e+02]\n",
      "right_fit is [-2.15929678e-04  3.92157909e-01  8.71958372e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  12%|█▏        | 9/75 [00:02<00:19,  3.45it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.76152927e-04  3.56328697e-01  2.61506304e+02]\n",
      "right_fit is [-1.17446951e-04  3.46741758e-01  8.69667882e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  13%|█▎        | 10/75 [00:03<00:18,  3.58it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.72216382e-04  3.57808571e-01  2.58067967e+02]\n",
      "right_fit is [-8.79167471e-05  3.12677304e-01  8.79887549e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  15%|█▍        | 11/75 [00:03<00:17,  3.72it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.62033660e-04  3.53683292e-01  2.55993518e+02]\n",
      "right_fit is [-1.23761279e-04  3.38622345e-01  8.74180965e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  16%|█▌        | 12/75 [00:03<00:16,  3.76it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.57369574e-04  3.52993312e-01  2.55193840e+02]\n",
      "right_fit is [-8.50762774e-05  3.11945014e-01  8.74455361e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  17%|█▋        | 13/75 [00:03<00:16,  3.87it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.52660834e-04  3.59256894e-01  2.45970441e+02]\n",
      "right_fit is [-5.99571557e-05  2.60124738e-01  8.99220843e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  19%|█▊        | 14/75 [00:04<00:15,  3.94it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.35946261e-04  3.46864465e-01  2.47626337e+02]\n",
      "right_fit is [2.77967317e-05 1.95962942e-01 9.04709191e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  20%|██        | 15/75 [00:04<00:15,  3.98it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.25114449e-04  3.39214881e-01  2.47708851e+02]\n",
      "right_fit is [-1.99957711e-04  3.85688778e-01  8.69146875e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  21%|██▏       | 16/75 [00:04<00:14,  3.97it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-1.98335691e-04  3.15554656e-01  2.53512592e+02]\n",
      "right_fit is [-2.14335411e-04  4.20085772e-01  8.48958922e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  23%|██▎       | 17/75 [00:04<00:14,  3.99it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-1.93926609e-04  3.08822884e-01  2.56049077e+02]\n",
      "right_fit is [-2.09525793e-04  4.30433138e-01  8.35808503e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  24%|██▍       | 18/75 [00:05<00:14,  4.03it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.30039482e-04  3.35540849e-01  2.51483722e+02]\n",
      "right_fit is [-1.94001003e-04  4.20392767e-01  8.33825029e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  25%|██▌       | 19/75 [00:05<00:13,  4.06it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.38212139e-04  3.41671641e-01  2.50183783e+02]\n",
      "right_fit is [-1.85370493e-04  4.18472483e-01  8.29389711e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  27%|██▋       | 20/75 [00:05<00:13,  3.99it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.22581216e-04  3.30149235e-01  2.49453109e+02]\n",
      "right_fit is [-1.87237603e-04  4.06570849e-01  8.39086348e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  28%|██▊       | 21/75 [00:05<00:13,  4.00it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-1.89592642e-04  3.06286987e-01  2.50035001e+02]\n",
      "right_fit is [-1.75257497e-04  3.85708363e-01  8.47910695e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  29%|██▉       | 22/75 [00:06<00:13,  4.01it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-1.89892340e-04  3.06358246e-01  2.47946826e+02]\n",
      "right_fit is [-1.75347819e-04  3.69053547e-01  8.58987470e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  31%|███       | 23/75 [00:06<00:13,  3.98it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-1.97625821e-04  3.12514599e-01  2.43991504e+02]\n",
      "right_fit is [-1.77049143e-04  3.53925751e-01  8.71174320e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  32%|███▏      | 24/75 [00:06<00:12,  3.98it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-1.85802609e-04  3.02665937e-01  2.43077488e+02]\n",
      "right_fit is [-1.93066326e-04  3.53110834e-01  8.77924734e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  33%|███▎      | 25/75 [00:06<00:12,  3.98it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.28065002e-04  3.28573366e-01  2.42421704e+02]\n",
      "right_fit is [-1.90351334e-04  3.56766249e-01  8.72820964e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  35%|███▍      | 26/75 [00:07<00:12,  4.00it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.29421208e-04  3.25278298e-01  2.44652736e+02]\n",
      "right_fit is [-1.78577064e-04  3.55396562e-01  8.68933925e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  36%|███▌      | 27/75 [00:07<00:12,  3.99it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.22687021e-04  3.20848908e-01  2.42366449e+02]\n",
      "right_fit is [-2.15803576e-04  3.65678946e-01  8.78631135e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  37%|███▋      | 28/75 [00:07<00:11,  3.94it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.50513442e-04  3.39712787e-01  2.39565445e+02]\n",
      "right_fit is [-2.65097283e-04  4.08006065e-01  8.72369889e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  39%|███▊      | 29/75 [00:07<00:11,  4.01it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.58397480e-04  3.46049845e-01  2.36014728e+02]\n",
      "right_fit is [-2.36375396e-04  3.66514473e-01  8.91313675e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  40%|████      | 30/75 [00:08<00:11,  4.04it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.59635397e-04  3.40979791e-01  2.40183586e+02]\n",
      "right_fit is [-2.62661925e-04  4.03786702e-01  8.78149421e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  41%|████▏     | 31/75 [00:08<00:10,  4.07it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.95307055e-04  3.59561488e-01  2.42258658e+02]\n",
      "right_fit is [-2.49918978e-04  4.08705136e-01  8.67836823e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  43%|████▎     | 32/75 [00:08<00:11,  3.84it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-3.30013885e-04  3.85624399e-01  2.41429893e+02]\n",
      "right_fit is [-2.25592995e-04  4.03603920e-01  8.60470008e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  44%|████▍     | 33/75 [00:08<00:11,  3.81it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-3.43392783e-04  3.95276037e-01  2.42928535e+02]\n",
      "right_fit is [-2.52022782e-04  4.44835565e-01  8.42504476e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  45%|████▌     | 34/75 [00:09<00:10,  3.83it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-3.32238573e-04  3.87420100e-01  2.42664764e+02]\n",
      "right_fit is [-2.01884809e-04  4.00205683e-01  8.56242121e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  47%|████▋     | 35/75 [00:09<00:10,  3.87it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-3.30894026e-04  3.89836594e-01  2.42700065e+02]\n",
      "right_fit is [-1.45800602e-04  3.76426487e-01  8.54105318e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  48%|████▊     | 36/75 [00:09<00:10,  3.80it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-3.59805015e-04  4.15359259e-01  2.39006618e+02]\n",
      "right_fit is [-1.40141504e-04  3.65593329e-01  8.56436390e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  49%|████▉     | 37/75 [00:09<00:09,  3.89it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-3.63390832e-04  4.21073210e-01  2.39446431e+02]\n",
      "right_fit is [-1.58448054e-04  3.82374779e-01  8.49030756e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  51%|█████     | 38/75 [00:10<00:09,  3.97it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-3.65795490e-04  4.25862086e-01  2.38615919e+02]\n",
      "right_fit is [-3.27515657e-04  5.14029941e-01  8.24865578e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  52%|█████▏    | 39/75 [00:10<00:08,  4.03it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-3.96782553e-04  4.53046238e-01  2.35024958e+02]\n",
      "right_fit is [-3.43229949e-04  5.34753123e-01  8.17341416e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  53%|█████▎    | 40/75 [00:10<00:08,  3.96it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-4.14641981e-04  4.70913484e-01  2.32033788e+02]\n",
      "right_fit is [-3.38942765e-04  5.44854132e-01  8.07706006e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  55%|█████▍    | 41/75 [00:10<00:08,  3.97it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-3.97188859e-04  4.61955471e-01  2.31060418e+02]\n",
      "right_fit is [-3.28496232e-04  5.32149551e-01  8.12778366e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  56%|█████▌    | 42/75 [00:11<00:08,  4.01it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-3.90107569e-04  4.59909192e-01  2.30508815e+02]\n",
      "right_fit is [-3.27061889e-04  5.37605900e-01  8.09732562e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  57%|█████▋    | 43/75 [00:11<00:08,  3.93it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-3.80307342e-04  4.58232439e-01  2.28953897e+02]\n",
      "right_fit is [-3.08640450e-04  5.23417894e-01  8.12689010e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  59%|█████▊    | 44/75 [00:11<00:08,  3.76it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-3.63015943e-04  4.49886295e-01  2.27878846e+02]\n",
      "right_fit is [-3.09989710e-04  5.16707500e-01  8.19300978e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  60%|██████    | 45/75 [00:11<00:07,  3.77it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-3.52206651e-04  4.45995602e-01  2.25072536e+02]\n",
      "right_fit is [-2.77567571e-04  4.78413231e-01  8.31681498e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  61%|██████▏   | 46/75 [00:12<00:07,  3.82it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-3.36828394e-04  4.37663616e-01  2.24372697e+02]\n",
      "right_fit is [-2.75541951e-04  4.73501552e-01  8.36112193e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  63%|██████▎   | 47/75 [00:12<00:07,  3.85it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-3.29969012e-04  4.34341762e-01  2.23464948e+02]\n",
      "right_fit is [-2.23097342e-04  4.35562949e-01  8.42084636e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  64%|██████▍   | 48/75 [00:12<00:07,  3.84it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-3.09362541e-04  4.22289313e-01  2.22433390e+02]\n",
      "right_fit is [-2.53177556e-04  4.46368183e-01  8.44838299e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  65%|██████▌   | 49/75 [00:13<00:06,  3.81it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-3.07076278e-04  4.20375985e-01  2.22759475e+02]\n",
      "right_fit is [-2.34365855e-04  4.43728734e-01  8.39464133e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  67%|██████▋   | 50/75 [00:13<00:06,  3.81it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.73068927e-04  4.00569458e-01  2.21193559e+02]\n",
      "right_fit is [-2.38610534e-04  4.33578093e-01  8.48431800e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  68%|██████▊   | 51/75 [00:13<00:06,  3.81it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.71196885e-04  4.01503061e-01  2.20018985e+02]\n",
      "right_fit is [-2.17954176e-04  4.21403382e-01  8.47338551e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  69%|██████▉   | 52/75 [00:13<00:06,  3.77it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.52830871e-04  3.88458428e-01  2.20881464e+02]\n",
      "right_fit is [-3.16892965e-04  4.99589792e-01  8.34356232e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  71%|███████   | 53/75 [00:14<00:05,  3.73it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.22637992e-04  3.61934923e-01  2.26435909e+02]\n",
      "right_fit is [-3.15350736e-04  5.16595433e-01  8.21609662e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  72%|███████▏  | 54/75 [00:14<00:05,  3.80it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.34697675e-04  3.72369833e-01  2.24310470e+02]\n",
      "right_fit is [-3.00615726e-04  5.07706828e-01  8.19695431e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  73%|███████▎  | 55/75 [00:14<00:05,  3.52it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.24832224e-04  3.62272664e-01  2.26223715e+02]\n",
      "right_fit is [-2.95196530e-04  5.10288916e-01  8.15290426e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  75%|███████▍  | 56/75 [00:14<00:05,  3.63it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-1.97872306e-04  3.37975560e-01  2.29381364e+02]\n",
      "right_fit is [-2.81889855e-04  4.98904426e-01  8.17767010e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  76%|███████▌  | 57/75 [00:15<00:06,  2.90it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-1.89307006e-04  3.29108505e-01  2.29989248e+02]\n",
      "right_fit is [-2.72738542e-04  4.86113229e-01  8.22727165e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  77%|███████▋  | 58/75 [00:15<00:05,  3.02it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-1.92008677e-04  3.29553078e-01  2.30070318e+02]\n",
      "right_fit is [-2.69578390e-04  4.88069601e-01  8.19917225e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  79%|███████▊  | 59/75 [00:16<00:05,  3.02it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-1.95976245e-04  3.29339075e-01  2.30249608e+02]\n",
      "right_fit is [-2.48455843e-04  4.68530321e-01  8.23789590e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  80%|████████  | 60/75 [00:16<00:04,  3.23it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.33568813e-04  3.48726465e-01  2.32533199e+02]\n",
      "right_fit is [-2.23414854e-04  4.74223083e-01  8.09762024e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  81%|████████▏ | 61/75 [00:16<00:04,  3.32it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.40895296e-04  3.46324942e-01  2.36479987e+02]\n",
      "right_fit is [-1.42699800e-04  4.19476721e-01  8.10189646e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  83%|████████▎ | 62/75 [00:16<00:03,  3.38it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.33839570e-04  3.35657754e-01  2.41058733e+02]\n",
      "right_fit is [-2.14959997e-04  4.74422570e-01  7.98522805e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  84%|████████▍ | 63/75 [00:17<00:03,  3.33it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.52620367e-04  3.45630049e-01  2.41679640e+02]\n",
      "right_fit is [-1.97458110e-04  4.62345453e-01  7.96470413e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  85%|████████▌ | 64/75 [00:17<00:03,  3.37it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.42170999e-04  3.33289031e-01  2.43499244e+02]\n",
      "right_fit is [-2.13455169e-04  4.65311798e-01  8.00249465e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  87%|████████▋ | 65/75 [00:17<00:02,  3.48it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.67278927e-04  3.45138513e-01  2.44970672e+02]\n",
      "right_fit is [-2.22521572e-04  4.74238609e-01  7.96355993e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  88%|████████▊ | 66/75 [00:18<00:02,  3.59it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.64710405e-04  3.43546105e-01  2.43702948e+02]\n",
      "right_fit is [-2.09110618e-04  4.50677773e-01  8.05751731e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  89%|████████▉ | 67/75 [00:18<00:02,  3.67it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.94278032e-04  3.61208669e-01  2.43440184e+02]\n",
      "right_fit is [-2.22393716e-04  4.60838751e-01  8.03076312e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  91%|█████████ | 68/75 [00:18<00:01,  3.65it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.69315377e-04  3.39789536e-01  2.46476114e+02]\n",
      "right_fit is [-2.17270693e-04  4.51440887e-01  8.05822760e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  92%|█████████▏| 69/75 [00:18<00:01,  3.64it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.69923750e-04  3.39420920e-01  2.45013752e+02]\n",
      "right_fit is [-1.95067796e-04  4.21518593e-01  8.15360650e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  93%|█████████▎| 70/75 [00:19<00:01,  3.68it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.79383383e-04  3.44552435e-01  2.45965336e+02]\n",
      "right_fit is [-2.01037784e-04  4.34196527e-01  8.07729902e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  95%|█████████▍| 71/75 [00:19<00:01,  3.73it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.48426235e-04  3.21803631e-01  2.46879514e+02]\n",
      "right_fit is [-1.72017929e-04  3.92708131e-01  8.23014801e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  96%|█████████▌| 72/75 [00:19<00:00,  3.72it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.44388630e-04  3.17967591e-01  2.48084448e+02]\n",
      "right_fit is [-1.00352926e-04  3.49198053e-01  8.26974277e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  97%|█████████▋| 73/75 [00:19<00:00,  3.68it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.22947028e-04  3.02389966e-01  2.48439869e+02]\n",
      "right_fit is [-4.73573324e-05  2.95366365e-01  8.40916247e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t:  99%|█████████▊| 74/75 [00:20<00:00,  3.70it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-2.01178297e-04  2.86237576e-01  2.49125908e+02]\n",
      "right_fit is [-2.11700649e-04  4.08532158e-01  8.25950371e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "t: 100%|██████████| 75/75 [00:20<00:00,  3.72it/s, now=None]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-1.85506869e-04  2.75458931e-01  2.49921312e+02]\n",
      "right_fit is [-3.09995433e-04  4.79232772e-01  8.14852000e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                                                            \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_fit is [-1.51111851e-04  2.50369120e-01  2.50265369e+02]\n",
      "right_fit is [-3.23172377e-04  4.80233292e-01  8.21156887e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \n",
      "t:   2%|▏         | 2/125 [48:44<00:44,  2.78it/s, now=None]\n",
      "                                                            [A\n",
      "t:   2%|▏         | 2/125 [48:44<00:44,  2.78it/s, now=None]\n",
      "t:   9%|▉         | 8/90 [43:26<00:40,  2.05it/s, now=None]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready test_videos_output/project_video.mp4\n",
      "CPU times: user 43.7 s, sys: 5.44 s, total: 49.1 s\n",
      "Wall time: 22.5 s\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "if os.path.exists(\"test_videos_output/\"):\n",
    "    print('Output videos will be saved to /test_videos_output')\n",
    "else: \n",
    "    print('Directory will be created: /test_videos_output')\n",
    "    os.makedirs(\"test_videos_output/\")\n",
    "\n",
    "white_output = 'test_videos_output/project_video.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "clip1 = VideoFileClip(\"test_videos/project_video.mp4\").subclip(0,3)\n",
    "##clip1 = VideoFileClip(\"test_videos/project_video.mp4\")\n",
    "\n",
    "count = 0\n",
    "left_fit_1d = []\n",
    "right_fit_1d = []\n",
    "\n",
    "#img = mpimg.imread('test_images/straight_lines1.jpg')\n",
    "#plt.imshow(process_image(img))\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play the video inline, or if you prefer find the video in your filesystem (should be in the same directory) and play it in your video player of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
